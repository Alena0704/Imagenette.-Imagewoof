{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Скачиваем данные по imagewoof2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе просмотра фотографий, а также изучения описания, стало ясно, что решаем задачу классификации породы собак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://s3.amazonaws.com/fast-ai-imageclas/imagewoof2.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импортируем требуемые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  # для отрисовки картиночек\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F  # Functional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls imagewoof2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls imagewoof2/train | wc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделяем данные на тренировочную и тестовую выборку, а также подгатавливаем наш pipeline для аугментации изображений. Такие возможны преобразования, которые написаны ниже:\n",
    "<li>Изменение размера изображений (все изображения разного размера)</li>\n",
    "<li>вырезание из изображения центальной части</li>\n",
    "<li>афинное преобразование изображения - shift у изображения + поворот</li>\n",
    "<li>зеркальный поворот по горизонтали</li>\n",
    "<li>вырезать случайную часть изображения</li>\n",
    "<li>закрасить определенную область изображения</li>\n",
    "<li>нормализация изображения</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_transforms = transforms.Compose(\n",
    "   [ transforms.Resize((250,250)), \n",
    "     transforms.CenterCrop(200), \n",
    "      #transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)), \n",
    "      transforms.RandomHorizontalFlip(), \n",
    "      #transforms.RandomCrop(32), \n",
    "      #transforms.RandomErasing(), \n",
    "      transforms.ToTensor(), #преобразование в тензор\n",
    "      transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]) \n",
    "     ])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize((200, 200)),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      #transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "                                     ])\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder('imagewoof2/train', transform=train_transforms)\n",
    "#trainset, valset = torch.utils.data.random_split(trainset, [7000, 2025])\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,shuffle=True, num_workers=1)\n",
    "\n",
    "#valloader = torch.utils.data.DataLoader(valset, batch_size=16,\n",
    "#                                          shuffle=True, num_workers=1)\n",
    "\n",
    "testset = torchvision.datasets.ImageFolder('imagewoof2/val', transform=test_transforms)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=16,\n",
    "                                         shuffle=False, num_workers=1)\n",
    "#какие породы собак мы распознаем:\n",
    "classes = ['Australian terrier', 'Border terrier', 'Samoyed', 'Beagle', 'Shih-Tzu', 'English foxhound', 'Rhodesian ridgeback', 'Dingo', 'Golden retriever', 'Old English sheepdog']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пишем простую архитектуру нейросети:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        # вызов конструктора предка nn.Module\n",
    "        super(SimpleConvNet, self).__init__()\n",
    "        # необходмо заранее знать, сколько каналов у картинки (сейчас = 3),\n",
    "        # которую будем подавать в сеть, больше ничего\n",
    "        # про входящие картинки знать не нужно\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5) #сверточный слой, ядро = 3х3, на выхое каналов - 6\n",
    "        #self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2) #снижающий размерность поступивших на него данных\n",
    "        self.bn1 = nn.BatchNorm2d(6) #слой, обеспечивающий пакетную (batch) нормализацию\n",
    "        #self.relu = nn.ReLU(inplace=True) #активационная функция\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=3, kernel_size=3)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        #self.bn2 = nn.BatchNorm2d(12)\n",
    "        #self.conv3 = nn.Conv2d(in_channels=12, out_channels=6, kernel_size=3)\n",
    "        #self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(28227, 2048)  # !!!  #- fully-connected, Dense в Keras, linear - tensorflow\n",
    "        self.drop = nn.Dropout(p=0.5)\n",
    "        \n",
    "        self.fc4 = nn.Linear(2048,  256)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        #self.bn5 = nn.BatchNorm1d(256)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "        \n",
    "        #self.max_batches_per_epoch=50\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        #x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        #x = self.relu(x)\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        #x=F.relu(self.conv3(x))\n",
    "        #x = self.bn2(x)\n",
    "        #x=self.pool3(F.relu(self.conv3(x)))\n",
    "        #x = F.relu(self.conv3(x))\n",
    "        #print(x.shape)\n",
    "        \n",
    "        x = x.view(-1, 28227)  # !!!\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        x = self.drop(x)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        #x = self.bn5(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SimpleConvNet()\n",
    "\n",
    "summary(net.cuda(), (3,200, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SimpleConvNet().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выбираем функцию потерь\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# выбираем алгоритм оптимизации и learning_rate\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(params = net.parameters(), lr=learning_rate) #оптимизатор\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучаем нейронную сеть:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "losses=[]\n",
    "total_correct=0\n",
    "total=0\n",
    "# итерируемся\n",
    "for epoch in tqdm_notebook(range(30)):\n",
    "    mean_loss = 0\n",
    "    batch_n = 0\n",
    "    running_loss = 0.0\n",
    "    print('Training')\n",
    "    for i, batch in enumerate(tqdm_notebook(trainloader)):\n",
    "        # так получаем текущий батч\n",
    "        X_batch, y_batch = batch\n",
    "        \n",
    "        # обнуляем веса\n",
    "        optimizer.zero_grad()\n",
    "        #print(X_batch.size())\n",
    "        # forward + backward + optimize\n",
    "        y_pred = net(X_batch.cuda())\n",
    "        #print(y_pred.size(),y_batch.size())\n",
    "        loss = loss_fn(y_pred, y_batch.cuda())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        mean_loss += float(loss)\n",
    "        batch_n += 1\n",
    "        # выведем текущий loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        \n",
    "        net.eval()\n",
    "        max_arg_output = torch.argmax(y_pred, dim=1)\n",
    "        total_correct += int(torch.sum(max_arg_output.cuda() == y_batch.cuda()))\n",
    "        total += X_batch.shape[0]\n",
    "        # выведем качество каждые 5 батчей\n",
    "        if i % 5 == 4:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 5))\n",
    "            losses.append(running_loss)\n",
    "            running_loss = 0.0\n",
    "    # Evaluationfor this fold\n",
    "    print('Starting testing')\n",
    "    mean_loss = 0\n",
    "    batch_n = 0\n",
    "    running_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm_notebook(valloader)):\n",
    "            X_batch, y_batch = batch\n",
    "            y_pred = net(X_batch.cuda())\n",
    "            loss = loss_fn(y_pred, y_batch.cuda())\n",
    "            mean_loss += float(loss)\n",
    "            batch_n += 1\n",
    "            running_loss += loss.item()\n",
    "            max_arg_output = torch.argmax(y_pred, dim=1)\n",
    "            total_correct += int(torch.sum(max_arg_output.cuda() == y_batch.cuda()))\n",
    "            total += X_batch.shape[0]\n",
    "            if i % 5 == 4:\n",
    "                print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 5))\n",
    "                losses.append(running_loss)\n",
    "                running_loss = 0.0\n",
    "    print('Test accuracy: {:.0%}'.format(total_correct/total))\n",
    "    ax.clear()\n",
    "    ax.plot(np.arange(len(losses)), losses)\n",
    "    plt.show()\n",
    "\n",
    "print('Обучение закончено')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Australian terrier', 'Border terrier', 'Samoyed', 'Beagle', 'Shih-Tzu', 'English foxhound', 'Rhodesian ridgeback', 'Dingo', 'Golden retriever', 'Old English sheepdog']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Посчитаем качество распознавания для каждого класса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in tqdm_notebook(testloader):\n",
    "        images, labels = data\n",
    "        #print(images)\n",
    "        y_pred = net(images.cuda())\n",
    "        \n",
    "        _, predicted = torch.max(y_pred, 1)\n",
    "        \n",
    "        c = (predicted.cpu().detach() == labels).squeeze()\n",
    "        \n",
    "        for i in range(len(labels)):\n",
    "            \n",
    "            label = labels[i]\n",
    "            #print(labels)\n",
    "            \n",
    "            class_correct[label] += c[i].item()\n",
    "            #print(class_correct)\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выведем матрицу ошибок, чтобы посмотреть, на каких классах модель ошибается. В дальнейшем попробуем увеличить веса для \"трудных\" классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_predict=[]\n",
    "class_true=[]\n",
    "with torch.no_grad():\n",
    "    for data in tqdm_notebook(testloader):\n",
    "        images, labels = data\n",
    "        #print(images)\n",
    "        y_pred = net(images.cuda())#.view(4, -1))\n",
    "        \n",
    "        _, predicted = torch.max(y_pred, 1)\n",
    "        \n",
    "        c = (predicted.cpu().detach() == labels).squeeze()\n",
    "        \n",
    "        for i in range(len(labels)):\n",
    "            class_predict.append(predicted.cpu()[i])\n",
    "            class_true.append(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(class_true,class_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_transforms = transforms.Compose(\n",
    "     [\n",
    "      transforms.Resize((300,300)),\n",
    "      transforms.CenterCrop(250),#224\n",
    "      transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n",
    "      #transforms.RandomHorizontalFlip(),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "     ])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize((250, 250)),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "                                     ])\n",
    "trainset = torchvision.datasets.ImageFolder('imagewoof2/train', transform=train_transforms)\n",
    "trainset, valset = torch.utils.data.random_split(trainset, [7000, 2025])\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=16,\n",
    "                                          shuffle=True, num_workers=1)\n",
    "\n",
    "valset.transform = test_transforms\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
    "                                          shuffle=True, num_workers=1)\n",
    "\n",
    "testset = torchvision.datasets.ImageFolder('imagewoof2/val', transform=test_transforms)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=16,\n",
    "                                         shuffle=False, num_workers=1)\n",
    "\n",
    "classes = ['Australian terrier', 'Border terrier', 'Samoyed', 'Beagle', 'Shih-Tzu', 'English foxhound', 'Rhodesian ridgeback', 'Dingo', 'Golden retriever', 'Old English sheepdog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = torchvision.models.resnet18(pretrained=False, num_classes=10)\n",
    "# transfer the model to the GPU\n",
    "model1 = model1.cuda()\n",
    "\n",
    "# loss function\n",
    "loss_fn = torch.nn.CrossEntropyLoss(weight = torch.Tensor([1.5,1.8,1.9,1.7,1.,1.,1.5,1.,1.,1.5]).cuda()) #указываем веса для кажого класса: для сложного класса, вес побольше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "# выбираем функцию потерь\n",
    "# We'll optimize all parameters\n",
    "optimizer = torch.optim.Adam(params = model1.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "losses=[]\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "# итерируемся\n",
    "for epoch in tqdm_notebook(range(10)):\n",
    "    mean_loss = 0\n",
    "    batch_n = 0\n",
    "    running_loss = 0.0\n",
    "    print('Training')\n",
    "    for i, batch in enumerate(tqdm_notebook(trainloader)):\n",
    "        # так получаем текущий батч\n",
    "        X_batch, y_batch = batch\n",
    "        \n",
    "        # обнуляем веса\n",
    "        optimizer.zero_grad()\n",
    "        #print(X_batch.size())\n",
    "        # forward + backward + optimize\n",
    "        y_pred = model1(X_batch.cuda())\n",
    "        \n",
    "        #print(y_pred)\n",
    "        loss = loss_fn(y_pred, y_batch.cuda())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        mean_loss += float(loss)\n",
    "        batch_n += 1\n",
    "        # выведем текущий loss\n",
    "        running_loss += loss.item()\n",
    "        # выведем качество каждые 5 батчей        \n",
    "        model1.eval()\n",
    "    \n",
    "        if i % 5 == 4:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 5))\n",
    "            losses.append(running_loss)\n",
    "            running_loss = 0.0\n",
    "    print('Starting testing')\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "    mean_loss = 0\n",
    "    batch_n = 0\n",
    "    running_loss = 0.0\n",
    "    # Evaluationfor this fold\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm_notebook(valloader)):\n",
    "            X_batch, y_batch = batch\n",
    "            y_pred = model1(X_batch.cuda())\n",
    "            loss = loss_fn(y_pred, y_batch.cuda())\n",
    "            mean_loss += float(loss)\n",
    "            batch_n += 1\n",
    "            # выведем текущий loss\n",
    "            running_loss += loss.item()\n",
    "            max_arg_output = torch.argmax(y_pred, dim=1)\n",
    "            total_correct += int(torch.sum(max_arg_output.cuda() == y_batch.cuda()))\n",
    "            total += X_batch.shape[0]\n",
    "            if i % 5 == 4:\n",
    "                print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 5))\n",
    "                losses.append(running_loss)\n",
    "                running_loss = 0.0\n",
    "    print('Test accuracy: {:.0%}'.format(total_correct/total))\n",
    "    ax.clear()\n",
    "    ax.plot(np.arange(len(losses)), losses)\n",
    "    plt.show()\n",
    "\n",
    "print('Обучение закончено')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
